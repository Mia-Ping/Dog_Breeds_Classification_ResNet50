{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"collapsed_sections":["KAfRCw3_pDR0","hGUZTU1gpQgp"]},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport tensorflow.keras.layers as L\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.preprocessing import image\n","metadata":{"id":"kuTuWIk6Z-7T","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T01:03:53.110697Z","iopub.execute_input":"2025-01-22T01:03:53.111086Z","iopub.status.idle":"2025-01-22T01:03:53.354709Z","shell.execute_reply.started":"2025-01-22T01:03:53.111052Z","shell.execute_reply":"2025-01-22T01:03:53.353569Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set seeds for reproducibility\nseed_value = 42\ntf.random.set_seed(seed_value)\n","metadata":{"id":"NFs9nYJzbpQy","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T01:03:53.355407Z","iopub.execute_input":"2025-01-22T01:03:53.356172Z","iopub.status.idle":"2025-01-22T01:03:53.361007Z","shell.execute_reply.started":"2025-01-22T01:03:53.35614Z","shell.execute_reply":"2025-01-22T01:03:53.359917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Define image dimensions and batch size\nimg_height = 224\nimg_width = 224\nbatch_size = 16","metadata":{"id":"3c03NMdObtYh","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T01:03:53.361917Z","iopub.execute_input":"2025-01-22T01:03:53.362158Z","iopub.status.idle":"2025-01-22T01:03:53.382027Z","shell.execute_reply.started":"2025-01-22T01:03:53.362132Z","shell.execute_reply":"2025-01-22T01:03:53.380658Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the inbuilt Stanford Dogs dataset from TensorFlow Datasets\n(raw_train, raw_validation), metadata = tfds.load(\n    'stanford_dogs',\n    split=['train[:80%]', 'train[20%:]'],  # 80% for training, 20% for validation\n    with_info=True,\n    as_supervised=True,  # Returns (image, label) pairs\n )","metadata":{"id":"xMAVzcMfbzJz","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T01:03:53.382875Z","iopub.execute_input":"2025-01-22T01:03:53.383119Z","iopub.status.idle":"2025-01-22T01:03:53.745171Z","shell.execute_reply.started":"2025-01-22T01:03:53.383095Z","shell.execute_reply":"2025-01-22T01:03:53.744178Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load dataset info\ndataset_info = tfds.builder('stanford_dogs').info\n\n# Extract class names\nclass_names = dataset_info.features['label'].names\nprint(class_names)","metadata":{"id":"2hQIzBzWwMVo","outputId":"a67f06a9-3d33-4708-bb72-8fcc12e44b69","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["['n02085620-chihuahua', 'n02085782-japanese_spaniel', 'n02085936-maltese_dog', 'n02086079-pekinese', 'n02086240-shih-tzu', 'n02086646-blenheim_spaniel', 'n02086910-papillon', 'n02087046-toy_terrier', 'n02087394-rhodesian_ridgeback', 'n02088094-afghan_hound', 'n02088238-basset', 'n02088364-beagle', 'n02088466-bloodhound', 'n02088632-bluetick', 'n02089078-black-and-tan_coonhound', 'n02089867-walker_hound', 'n02089973-english_foxhound', 'n02090379-redbone', 'n02090622-borzoi', 'n02090721-irish_wolfhound', 'n02091032-italian_greyhound', 'n02091134-whippet', 'n02091244-ibizan_hound', 'n02091467-norwegian_elkhound', 'n02091635-otterhound', 'n02091831-saluki', 'n02092002-scottish_deerhound', 'n02092339-weimaraner', 'n02093256-staffordshire_bullterrier', 'n02093428-american_staffordshire_terrier', 'n02093647-bedlington_terrier', 'n02093754-border_terrier', 'n02093859-kerry_blue_terrier', 'n02093991-irish_terrier', 'n02094114-norfolk_terrier', 'n02094258-norwich_terrier', 'n02094433-yorkshire_terrier', 'n02095314-wire-haired_fox_terrier', 'n02095570-lakeland_terrier', 'n02095889-sealyham_terrier', 'n02096051-airedale', 'n02096177-cairn', 'n02096294-australian_terrier', 'n02096437-dandie_dinmont', 'n02096585-boston_bull', 'n02097047-miniature_schnauzer', 'n02097130-giant_schnauzer', 'n02097209-standard_schnauzer', 'n02097298-scotch_terrier', 'n02097474-tibetan_terrier', 'n02097658-silky_terrier', 'n02098105-soft-coated_wheaten_terrier', 'n02098286-west_highland_white_terrier', 'n02098413-lhasa', 'n02099267-flat-coated_retriever', 'n02099429-curly-coated_retriever', 'n02099601-golden_retriever', 'n02099712-labrador_retriever', 'n02099849-chesapeake_bay_retriever', 'n02100236-german_short-haired_pointer', 'n02100583-vizsla', 'n02100735-english_setter', 'n02100877-irish_setter', 'n02101006-gordon_setter', 'n02101388-brittany_spaniel', 'n02101556-clumber', 'n02102040-english_springer', 'n02102177-welsh_springer_spaniel', 'n02102318-cocker_spaniel', 'n02102480-sussex_spaniel', 'n02102973-irish_water_spaniel', 'n02104029-kuvasz', 'n02104365-schipperke', 'n02105056-groenendael', 'n02105162-malinois', 'n02105251-briard', 'n02105412-kelpie', 'n02105505-komondor', 'n02105641-old_english_sheepdog', 'n02105855-shetland_sheepdog', 'n02106030-collie', 'n02106166-border_collie', 'n02106382-bouvier_des_flandres', 'n02106550-rottweiler', 'n02106662-german_shepherd', 'n02107142-doberman', 'n02107312-miniature_pinscher', 'n02107574-greater_swiss_mountain_dog', 'n02107683-bernese_mountain_dog', 'n02107908-appenzeller', 'n02108000-entlebucher', 'n02108089-boxer', 'n02108422-bull_mastiff', 'n02108551-tibetan_mastiff', 'n02108915-french_bulldog', 'n02109047-great_dane', 'n02109525-saint_bernard', 'n02109961-eskimo_dog', 'n02110063-malamute', 'n02110185-siberian_husky', 'n02110627-affenpinscher', 'n02110806-basenji', 'n02110958-pug', 'n02111129-leonberg', 'n02111277-newfoundland', 'n02111500-great_pyrenees', 'n02111889-samoyed', 'n02112018-pomeranian', 'n02112137-chow', 'n02112350-keeshond', 'n02112706-brabancon_griffon', 'n02113023-pembroke', 'n02113186-cardigan', 'n02113624-toy_poodle', 'n02113712-miniature_poodle', 'n02113799-standard_poodle', 'n02113978-mexican_hairless', 'n02115641-dingo', 'n02115913-dhole', 'n02116738-african_hunting_dog']\n"]}],"execution_count":null},{"cell_type":"code","source":"# # Define the Learning Rate Scheduler (Exponential Decay)\n# initial_learning_rate = 0.01\n# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n#     initial_learning_rate=initial_learning_rate,\n#     decay_steps=100000,  # Number of steps after which the learning rate will decay\n#     decay_rate=0.96,     # The rate at which the learning rate decays\n#     staircase=True)\n\n# Monitor validation loss and reduce the learning rate when it stops improving\nlr_scheduler = ReduceLROnPlateau(\n    monitor='val_accuracy',\n    factor=0.5,  # Reduce learning rate by a factor of 0.5\n    patience=3,  # Number of epochs with no improvement before reducing LR\n    verbose=1,  # Print a message when learning rate is reduced\n    min_lr=1e-6  # Minimum learning rate\n)\n","metadata":{"id":"i_LaFWO7YqmV","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T01:03:53.745942Z","iopub.execute_input":"2025-01-22T01:03:53.746169Z","iopub.status.idle":"2025-01-22T01:03:53.750339Z","shell.execute_reply.started":"2025-01-22T01:03:53.746144Z","shell.execute_reply":"2025-01-22T01:03:53.749519Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{"id":"KAfRCw3_pDR0"}},{"cell_type":"code","source":"# Convert TFDS dataset to NumPy arrays\ndef tfds_to_numpy(dataset):\n    images = []\n    labels = []\n    for img, label in tfds.as_numpy(dataset):\n        images.append(tf.image.resize(img, (img_height, img_width)).numpy())\n        labels.append(label)\n    return np.array(images), np.array(labels)\n\n\ntrain_images, train_labels = tfds_to_numpy(raw_train)\nval_images, val_labels = tfds_to_numpy(raw_validation)","metadata":{"id":"AUcOuh4RiAW-","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T01:03:53.763705Z","iopub.execute_input":"2025-01-22T01:03:53.763928Z","iopub.status.idle":"2025-01-22T01:04:27.790493Z","shell.execute_reply.started":"2025-01-22T01:03:53.763905Z","shell.execute_reply":"2025-01-22T01:04:27.789315Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define custom augmentation function\ndef random_crop(img):\n    img = tf.image.random_crop(img, size=[img_height, img_width, 3])  # Random crop to required size\n    return img\n\n# Data Augmentation: Apply random transformations to the image for better generalization\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,  # Normalize pixel values to [0, 1]\n    rotation_range=45,  # Randomly rotate images\n    width_shift_range=0.2,  # Randomly shift images horizontally\n    height_shift_range=0.2,  # Randomly shift images vertically\n    shear_range=0.2,  # Randomly shear images\n    zoom_range=0.2,  # Randomly zoom images\n    horizontal_flip=True,  # Randomly flip images horizontally\n    fill_mode='nearest',  # Fill missing pixels after transformations\n    brightness_range=[0.8, 1.2],\n    channel_shift_range=50.0, # change range of colors\n    preprocessing_function=random_crop)\n","metadata":{"id":"LibHXF45ZOfd","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T01:04:27.79142Z","iopub.execute_input":"2025-01-22T01:04:27.791677Z","iopub.status.idle":"2025-01-22T01:04:27.796942Z","shell.execute_reply.started":"2025-01-22T01:04:27.791652Z","shell.execute_reply":"2025-01-22T01:04:27.795897Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"validation_datagen = ImageDataGenerator(rescale=1./255)  # Only rescale for validation","metadata":{"id":"2SLRon4Zi4aT","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T01:04:27.797686Z","iopub.execute_input":"2025-01-22T01:04:27.797975Z","iopub.status.idle":"2025-01-22T01:04:27.809306Z","shell.execute_reply.started":"2025-01-22T01:04:27.797946Z","shell.execute_reply":"2025-01-22T01:04:27.808446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create data generators\ntrain_generator = train_datagen.flow(\n    train_images, train_labels, batch_size=batch_size\n)\n\nvalidation_generator = validation_datagen.flow(\n    val_images, val_labels, batch_size=batch_size\n)","metadata":{"id":"6tFNkIvmi_CY","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T01:04:27.810275Z","iopub.execute_input":"2025-01-22T01:04:27.810499Z","iopub.status.idle":"2025-01-22T01:04:27.818622Z","shell.execute_reply.started":"2025-01-22T01:04:27.810476Z","shell.execute_reply":"2025-01-22T01:04:27.817782Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(train_generator))\nprint(len(validation_generator))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T01:04:27.81945Z","iopub.execute_input":"2025-01-22T01:04:27.819669Z","iopub.status.idle":"2025-01-22T01:04:27.828405Z","shell.execute_reply.started":"2025-01-22T01:04:27.819649Z","shell.execute_reply":"2025-01-22T01:04:27.827444Z"},"id":"aT8vXz4-reHB"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Photo Preview","metadata":{"id":"hGUZTU1gpQgp"}},{"cell_type":"code","source":"# Visualize a batch of images after augmentation\nbatch = next(train_generator)  # Get one batch of data\nimages, labels = batch  # Unpack the images and labels from the batch\n\nplt.figure(figsize=(10, 10))\n\n# Plot 16 images in a 4x4 grid\nfor i in range(16):  # Loop through the batch of 16 images\n    plt.subplot(4, 4, i + 1)\n    plt.imshow(images[i])  # Use the augmented image\n    breed_name = label_map[labels[i]]  # Map the label to the breed name\n    breed_name = breed_name.split('-')[-1]  # Only use the breed name (ignore the label number)\n    plt.title(f\"{breed_name}\")\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T01:04:27.839001Z","iopub.execute_input":"2025-01-22T01:04:27.839212Z","iopub.status.idle":"2025-01-22T01:04:29.485523Z","shell.execute_reply.started":"2025-01-22T01:04:27.83919Z","shell.execute_reply":"2025-01-22T01:04:29.484342Z"},"id":"Ma63oxOLreHC"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Import ResNet50","metadata":{"id":"xhEKdJN0qOEn"}},{"cell_type":"code","source":"# Load the EfficientNetB0 architecture from Keras, without pre-trained weights\nbase_model = tf.keras.applications.ResNet50(\n    include_top=False,  # Exclude the final fully connected layer\n    weights='imagenet',  # Load pretrained weights from ImageNet\n    input_shape=(img_height, img_width, 3)\n)","metadata":{"id":"ajBNI_thckME","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T01:04:29.486374Z","iopub.execute_input":"2025-01-22T01:04:29.486647Z","iopub.status.idle":"2025-01-22T01:04:30.663259Z","shell.execute_reply.started":"2025-01-22T01:04:29.486619Z","shell.execute_reply":"2025-01-22T01:04:30.661985Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Freeze the base_model layers (don't train them)\nfor layer in base_model.layers:\n    layer.trainable = False","metadata":{"id":"qjA8F69Fqj_h","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T01:04:30.664048Z","iopub.execute_input":"2025-01-22T01:04:30.664278Z","iopub.status.idle":"2025-01-22T01:04:30.671428Z","shell.execute_reply.started":"2025-01-22T01:04:30.664253Z","shell.execute_reply":"2025-01-22T01:04:30.670334Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add custom layers on top\nx = base_model.output\nx = layers.GlobalAveragePooling2D()(x)  # Apply global average pooling to the output\nx = layers.Dense(256, activation='relu')(x)  # Add a fully connected layer\nx = layers.Dense(120, activation='softmax')(x)  # Output layer for 120 classes (dog breeds)","metadata":{"id":"e3BVsGlRqEpn","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T01:04:30.672087Z","iopub.execute_input":"2025-01-22T01:04:30.672398Z","iopub.status.idle":"2025-01-22T01:04:30.729303Z","shell.execute_reply.started":"2025-01-22T01:04:30.672356Z","shell.execute_reply":"2025-01-22T01:04:30.728326Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Build, Compile and Train the Model","metadata":{"id":"Lb9uoVgoqzzr"}},{"cell_type":"code","source":"# Create the final model\n# model = Model(inputs=base_model.input, outputs=x)\nmodel = models.Model(inputs=base_model.input, outputs=x)","metadata":{"id":"RVTVwf_VexQ-","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T01:04:30.73016Z","iopub.execute_input":"2025-01-22T01:04:30.730387Z","iopub.status.idle":"2025-01-22T01:04:30.75839Z","shell.execute_reply.started":"2025-01-22T01:04:30.730363Z","shell.execute_reply":"2025-01-22T01:04:30.757524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile the model\nmodel.compile(\n    optimizer=Adam(learning_rate=1e-4),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Define EarlyStopping callback to stop training early\nearly_stopping = EarlyStopping(\n    monitor='val_accuracy',\n    patience=30,               # Stop training if no improvement in 30 epochs\n    verbose=1,                # Print a message when training is stopped early\n    restore_best_weights=True # Restore the best model weights\n)\n\n\n# Train the model\nhistory = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=100,\n    callbacks=[lr_scheduler, early_stopping]  # Use early stopping and learning rate scheduler\n)","metadata":{"id":"i_OnISHJrBdm","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T01:04:30.759403Z","iopub.execute_input":"2025-01-22T01:04:30.759698Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Fine-tune the Model","metadata":{"id":"OLOMilUDt7cI"}},{"cell_type":"code","source":"# Fine-tune the model by unfreezing some layers\nfor layer in base_model.layers[-150:]:  # Unfreeze the last 100 layers\n    layer.trainable = True","metadata":{"id":"t1oDhoif6g8c","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Recompile the model after unfreezing layers\noptimizer = tf.keras.optimizers.SGD(learning_rate=1e-4, momentum=0.9)\n\nmodel.compile(\n    optimizer=optimizer,\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"id":"GCqdWZfnuUrk","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"id":"4enGvegfeHR_","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fine-tune the model with the updated optimizer and the same learning rate scheduler\nhistory_fine_tune = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=150,\n    callbacks=[lr_scheduler, early_stopping] # Continue using the LR scheduler and early stopping\n)","metadata":{"id":"vitXlMXvulSz","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model\nloss, accuracy = model.evaluate(validation_generator)\nprint(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\nprint(f\"Validation Loss: {loss:.4f}\")","metadata":{"id":"l3_DTF4Pws67","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Plot training and validation accuracy/loss","metadata":{"id":"6F1IbeNQw7MV"}},{"cell_type":"code","source":"# Get the training and validation metrics from the history object\nacc = history_fine_tune.history['accuracy']\nval_acc = history_fine_tune.history['val_accuracy']\nloss = history_fine_tune.history['loss']\nval_loss = history_fine_tune.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.figure(figsize=(14, 7))\n\n# Plot Training and Validation Loss with Different Colors\nplt.subplot(1, 2, 1)\nplt.plot(epochs, loss, label='Training Loss', color='blue')\nplt.plot(epochs, val_loss, label='Validation Loss', color='red')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n# Plot Training and Validation Accuracy with Different Colors\nplt.subplot(1, 2, 2)\nplt.plot(epochs, acc, label='Training Accuracy', color='green')\nplt.plot(epochs, val_acc, label='Validation Accuracy', color='orange')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"-PoOAqgExGbC","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the trained model using the recommended Keras format\nmodel.save('dog_breeds_resnet50_model.keras')","metadata":{"id":"f08ewSg4sOhL","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the saved model\nloaded_model = tf.keras.models.load_model('dog_breeds_resnet50_model.keras')","metadata":{"id":"aHl6G0FKsXxO","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get true labels and predictions for the test dataset\nY_true_test = []\nY_pred_test = []\n#\nfor images, labels in validation_generator:\n    Y_true_test.extend(labels) # Collect true labels\n    Y_pred_prob = model.predict(images, verbose=0) # Get predicted probabilities\n    Y_pred_test.extend(np.argmax(Y_pred_prob, axis=1)) # Convert probabilities to predicted labels\n\n# Calculate Accuracy, Precision, Recall, F1-score\naccuracy = accuracy_score(Y_true_test, Y_pred_test)\nprecision = precision_score(Y_true_test, Y_pred_test, average='weighted')  # 'weighted' for multi-class classification\nrecall = recall_score(Y_true_test, Y_pred_test, average='weighted')\nf1 = f1_score(Y_true_test, Y_pred_test, average='weighted')\n\n# Print the evaluation metrics\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1-score: {f1:.4f}\")\n","metadata":{"id":"FFwVflJOTbGO","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate confusion matrix\nconf_matrix = confusion_matrix(Y_true_test, Y_pred_test)\n\n# Create a heatmap of the confusion matrix\nplt.figure(figsize=(12, 10))  # Adjust the figure size to fit the large matrix\n\n# If you only want to focus on the top 10 most confusing pairs,\n# you can slice your confusion matrix like so:\ntop_10_conf_matrix = conf_matrix[:10, :10]\n\nsns.heatmap(top_10_conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.title('Confusion Matrix (Top 10 classes)')\nplt.show()","metadata":{"id":"LTJw3PbYfpI8","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Test a Picture","metadata":{"id":"EKQlFAlcuMH2"}},{"cell_type":"code","source":"# Function to preprocess the image\ndef preprocess_image(image_path, target_size=(224, 224)):\n    \"\"\"\n    Preprocess the image for prediction.\n    Args:\n        image_path: Path to the input image.\n        target_size: Tuple specifying the input size for the model.\n    Returns:\n        Preprocessed image as a numpy array.\n    \"\"\"\n    img = load_img(image_path, target_size=target_size)  # Load and resize the image\n    img_array = img_to_array(img)  # Convert to numpy array\n    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n    img_array = img_array / 255.0  # Normalize pixel values\n    return img_array\n\n# Path to the test image\nimage_path = '/Users/pingsusu/Downloads/Dog 2.png'\n\n# Preprocess the test image\ninput_image = preprocess_image(image_path)\n\n# Make prediction\npredictions = model.predict(input_image)\npredicted_class_index = np.argmax(predictions)  # Get the index of the highest probability\npredicted_class_name = class_names[predicted_class_index]  # Map to the breed name\n\n# Display the image and prediction\nplt.figure(figsize=(6, 6))\nimg = load_img(image_path)\nplt.imshow(img)\nplt.axis('off')\nplt.title(f\"Predicted Breed: {predicted_class_name}\", fontsize=16)\nplt.show()\n\nprint(f\"The predicted breed is: {predicted_class_name}\")\n","metadata":{"id":"cKrKVvzPrx-6"},"outputs":[],"execution_count":null}]}